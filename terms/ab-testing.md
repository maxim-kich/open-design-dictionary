---
category: ux
type: methodology
tags: [testing]
---

# A/B Testing

## Definition
A quantitative method that compares two versions of a design by randomly showing each version to users and measuring which performs better on specific metrics. A/B testing provides statistical evidence for design decisions by measuring actual behavior.

## Examples
- Testing two different button colors to see which has higher click-through rate
- Comparing two checkout flows to determine which has better completion rate

## Do's and Don'ts

**Do's**
- Test one variable at a time
- Define success metrics before testing
- Ensure statistical significance before concluding
- Run tests long enough for reliable data
- Test with sufficient traffic volume
- Document learnings for future reference

**Don'ts**
- Test too many variables simultaneously
- Stop tests prematurely based on early results
- Make conclusions with insufficient sample size
- Ignore statistical significance
- Test without clear hypotheses
- Use A/B testing for exploratory research

## References
- [Nielsen Norman Group: A/B Testing](https://www.nngroup.com/articles/ab-testing-usability-engineering/)
- [Optimizely: A/B Testing Guide](https://www.optimizely.com/optimization-glossary/ab-testing/)
